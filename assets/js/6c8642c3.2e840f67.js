"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4239],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>f});var a=n(7294);function l(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function s(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?s(Object(n),!0).forEach((function(t){l(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):s(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,a,l=function(e,t){if(null==e)return{};var n,a,l={},s=Object.keys(e);for(a=0;a<s.length;a++)n=s[a],t.indexOf(n)>=0||(l[n]=e[n]);return l}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(a=0;a<s.length;a++)n=s[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(l[n]=e[n])}return l}var i=a.createContext({}),d=function(e){var t=a.useContext(i),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},u=function(e){var t=d(e.components);return a.createElement(i.Provider,{value:t},e.children)},p="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},c=a.forwardRef((function(e,t){var n=e.components,l=e.mdxType,s=e.originalType,i=e.parentName,u=o(e,["components","mdxType","originalType","parentName"]),p=d(n),c=l,f=p["".concat(i,".").concat(c)]||p[c]||m[c]||s;return n?a.createElement(f,r(r({ref:t},u),{},{components:n})):a.createElement(f,r({ref:t},u))}));function f(e,t){var n=arguments,l=t&&t.mdxType;if("string"==typeof e||l){var s=n.length,r=new Array(s);r[0]=c;var o={};for(var i in t)hasOwnProperty.call(t,i)&&(o[i]=t[i]);o.originalType=e,o[p]="string"==typeof e?e:l,r[1]=o;for(var d=2;d<s;d++)r[d]=n[d];return a.createElement.apply(null,r)}return a.createElement.apply(null,n)}c.displayName="MDXCreateElement"},1825:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>i,contentTitle:()=>r,default:()=>m,frontMatter:()=>s,metadata:()=>o,toc:()=>d});var a=n(7462),l=(n(7294),n(3905));const s={title:"Introduction",slug:"/docs"},r=void 0,o={unversionedId:"docs/introduction",id:"docs/introduction",title:"Introduction",description:"Jan can be used to build a variety of AI use cases, at every level of the stack:",source:"@site/docs/docs/01_introduction.md",sourceDirName:"docs",slug:"/docs",permalink:"/docs",draft:!1,editUrl:"https://github.com/janhq/jan/tree/main/docs/docs/docs/01_introduction.md",tags:[],version:"current",lastUpdatedBy:"Faisal Amir",lastUpdatedAt:1700225581,formattedLastUpdatedAt:"Nov 17, 2023",sidebarPosition:1,frontMatter:{title:"Introduction",slug:"/docs"},sidebar:"docsSidebar",next:{title:"Linux",permalink:"/getting-started/install/linux"}},i={},d=[{value:"Resources",id:"resources",level:2},{value:"Key Concepts",id:"key-concepts",level:2},{value:"Modules",id:"modules",level:3},{value:"Local Filesystem",id:"local-filesystem",level:3},{value:"Jan: a &quot;global&quot; assistant",id:"jan-a-global-assistant",level:3}],u={toc:d},p="wrapper";function m(e){let{components:t,...n}=e;return(0,l.kt)(p,(0,a.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("p",null,"Jan can be used to build a variety of AI use cases, at every level of the stack:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"An OpenAI compatible API, with feature parity for ",(0,l.kt)("inlineCode",{parentName:"li"},"models"),", ",(0,l.kt)("inlineCode",{parentName:"li"},"assistants"),", ",(0,l.kt)("inlineCode",{parentName:"li"},"files")," and more"),(0,l.kt)("li",{parentName:"ul"},"A standard data format on top of the user's local filesystem, allowing for transparency and composability"),(0,l.kt)("li",{parentName:"ul"},"Automatically package and distribute to Mac, Windows and Linux. Cloud coming soon"),(0,l.kt)("li",{parentName:"ul"},"An UI kit to customize user interactions with ",(0,l.kt)("inlineCode",{parentName:"li"},"assistants")," and more"),(0,l.kt)("li",{parentName:"ul"},"A standalone inference engine for low level use cases")),(0,l.kt)("h2",{id:"resources"},"Resources"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Create an AI assistant"),(0,l.kt)("li",{parentName:"ul"},"Run an OpenAI compatible API endpoint"),(0,l.kt)("li",{parentName:"ul"},"Build a VSCode plugin with a local model"),(0,l.kt)("li",{parentName:"ul"},"Build a Jan platform module")),(0,l.kt)("h2",{id:"key-concepts"},"Key Concepts"),(0,l.kt)("h3",{id:"modules"},"Modules"),(0,l.kt)("p",null,"Jan is comprised of system-level modules that mirror OpenAI\u2019s, exposing similar APIs and objects"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Modules are modular, atomic implementations of a single OpenAI-compatible endpoint"),(0,l.kt)("li",{parentName:"ul"},"Modules can be swapped out for alternate implementations",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"The default ",(0,l.kt)("inlineCode",{parentName:"li"},"messages")," module persists messages in thread-specific ",(0,l.kt)("inlineCode",{parentName:"li"},".json")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"messages-postgresql")," uses Postgres for production-grade cloud-native environments")))),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Jan Module"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"),(0,l.kt)("th",{parentName:"tr",align:null},"API Docs"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"Chat"),(0,l.kt)("td",{parentName:"tr",align:null},"Inference"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("a",{parentName:"td",href:"/api/chat"},"/chat"))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"Models"),(0,l.kt)("td",{parentName:"tr",align:null},"Models"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("a",{parentName:"td",href:"/api/model"},"/model"))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"Assistants"),(0,l.kt)("td",{parentName:"tr",align:null},"Apps"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("a",{parentName:"td",href:"/api/assistant"},"/assistant"))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"Threads"),(0,l.kt)("td",{parentName:"tr",align:null},"Conversations"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("a",{parentName:"td",href:"/api/thread"},"/thread"))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"Messages"),(0,l.kt)("td",{parentName:"tr",align:null},"Messages"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("a",{parentName:"td",href:"/api/message"},"/message"))))),(0,l.kt)("h3",{id:"local-filesystem"},"Local Filesystem"),(0,l.kt)("p",null,"Jan use the local filesystem for data persistence, similar to VSCode. This allows for composability and tinkerability."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sh="},"/janroot               # Jan's root folder (e.g. ~/jan)\n    /models            # For raw AI models\n    /threads           # For conversation history\n    /assistants        # For AI assistants' configs, knowledge, etc.\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sh="},"/models\n    /modelA\n        model.json        # Default model settings\n        llama-7b-q4.gguf  # Model binaries\n        llama-7b-q5.gguf  # Include different quantizations\n/threads\n    /jan-unixstamp-salt\n        model.json        # Overrides assistant/model-level model settings\n        thread.json       # thread metadata (e.g. subject)\n        messages.json     # messages\n        content.json      # What is this?\n        files/            # Future for RAG\n/assistants\n    /jan\n        assistant.json    # Assistant configs (see below)\n\n        # For any custom code\n        package.json      # Import npm modules\n                          # e.g. Langchain, Llamaindex\n        /src              # Supporting files (needs better name)\n            index.js      # Entrypoint\n            process.js    # For electron IPC processes (needs better name)\n\n        # `/threads` at root level\n        # `/models` at root level\n    /shakespeare\n        assistant.json\n        model.json        # Creator chooses model and settings\n        package.json\n        /src\n            index.js\n            process.js\n\n        /threads          # Assistants remember conversations in the future\n        /models           # Users can upload custom models\n            /finetuned-model\n")),(0,l.kt)("h3",{id:"jan-a-global-assistant"},'Jan: a "global" assistant'),(0,l.kt)("p",null,'Jan ships with a default assistant "Jan" that lets users chat with any open source model out-of-the-box.'),(0,l.kt)("p",null,"This assistant is defined in ",(0,l.kt)("inlineCode",{parentName:"p"},"/jan"),". It is a generic assistant to illustrate power of Jan. In the future, it will support additional features e.g. multi-assistant conversations"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},'Your Assistant "Jan" lets you pick any model that is in the root /models folder'),(0,l.kt)("li",{parentName:"ul"},"Right panel: pick LLM model and set model parameters"),(0,l.kt)("li",{parentName:"ul"},"Jan\u2019s threads will be at root level"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"model.json")," will reflect model chosen for that session"),(0,l.kt)("li",{parentName:"ul"},"Be able to \u201cadd\u201d other assistants in the future"),(0,l.kt)("li",{parentName:"ul"},"Jan\u2019s files will be at thread level"),(0,l.kt)("li",{parentName:"ul"},"Jan is not a persistent memory assistant")))}m.isMDXComponent=!0}}]);