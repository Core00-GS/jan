"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[3316],{3905:(e,t,n)=>{n.d(t,{Zo:()=>m,kt:()=>k});var a=n(7294);function l(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){l(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,l=function(e,t){if(null==e)return{};var n,a,l={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(l[n]=e[n]);return l}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(l[n]=e[n])}return l}var p=a.createContext({}),d=function(e){var t=a.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},m=function(e){var t=d(e.components);return a.createElement(p.Provider,{value:t},e.children)},s="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},c=a.forwardRef((function(e,t){var n=e.components,l=e.mdxType,r=e.originalType,p=e.parentName,m=i(e,["components","mdxType","originalType","parentName"]),s=d(n),c=l,k=s["".concat(p,".").concat(c)]||s[c]||u[c]||r;return n?a.createElement(k,o(o({ref:t},m),{},{components:n})):a.createElement(k,o({ref:t},m))}));function k(e,t){var n=arguments,l=t&&t.mdxType;if("string"==typeof e||l){var r=n.length,o=new Array(r);o[0]=c;var i={};for(var p in t)hasOwnProperty.call(t,p)&&(i[p]=t[p]);i.originalType=e,i[s]="string"==typeof e?e:l,o[1]=i;for(var d=2;d<r;d++)o[d]=n[d];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}c.displayName="MDXCreateElement"},267:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>o,default:()=>u,frontMatter:()=>r,metadata:()=>i,toc:()=>d});var a=n(7462),l=(n(7294),n(3905));const r={title:"Models"},o=void 0,i={unversionedId:"specs/models",id:"specs/models",title:"Models",description:"Draft Specification: functionality has not been implemented yet.",source:"@site/docs/specs/models.md",sourceDirName:"specs",slug:"/specs/models",permalink:"/specs/models",draft:!1,editUrl:"https://github.com/janhq/jan/tree/main/docs/docs/specs/models.md",tags:[],version:"current",lastUpdatedBy:"Daniel",lastUpdatedAt:1700408569,formattedLastUpdatedAt:"Nov 19, 2023",frontMatter:{title:"Models"},sidebar:"docsSidebar",previous:{title:"Chats",permalink:"/specs/chats"},next:{title:"Threads",permalink:"/specs/threads"}},p={},d=[{value:"Overview",id:"overview",level:2},{value:"User Objectives",id:"user-objectives",level:3},{value:"Models Folder",id:"models-folder",level:2},{value:"Model Object",id:"model-object",level:2},{value:"Model Source",id:"model-source",level:3},{value:"Model Formats",id:"model-formats",level:3},{value:"Multiple binaries",id:"multiple-binaries",level:3},{value:"Models API",id:"models-api",level:2},{value:"Get Model",id:"get-model",level:3},{value:"Request",id:"request",level:4},{value:"Response",id:"response",level:4},{value:"List models",id:"list-models",level:3},{value:"Request",id:"request-1",level:4},{value:"Response",id:"response-1",level:4},{value:"Delete Model",id:"delete-model",level:3},{value:"Request",id:"request-2",level:4},{value:"Response",id:"response-2",level:4},{value:"Start Model",id:"start-model",level:3},{value:"Request",id:"request-3",level:4},{value:"Response",id:"response-3",level:4},{value:"Stop Model",id:"stop-model",level:3},{value:"Request",id:"request-4",level:4},{value:"Response",id:"response-4",level:4},{value:"Download Model",id:"download-model",level:3},{value:"Request",id:"request-5",level:4},{value:"Response",id:"response-5",level:4},{value:"Examples",id:"examples",level:2},{value:"Pre-loaded Models",id:"pre-loaded-models",level:3},{value:"Azure OpenAI",id:"azure-openai",level:3},{value:"Multiple quantizations",id:"multiple-quantizations",level:3},{value:"Multiple model partitions",id:"multiple-model-partitions",level:3},{value:"Your locally fine-tuned model",id:"your-locally-fine-tuned-model",level:3}],m={toc:d},s="wrapper";function u(e){let{components:t,...n}=e;return(0,l.kt)(s,(0,a.Z)({},m,n,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("admonition",{type:"warning"},(0,l.kt)("p",{parentName:"admonition"},"Draft Specification: functionality has not been implemented yet. "),(0,l.kt)("p",{parentName:"admonition"},"Feedback: ",(0,l.kt)("a",{parentName:"p",href:"https://hackmd.io/ulO3uB1AQCqLa5SAAMFOQw"},"HackMD: Models Spec")," ")),(0,l.kt)("h2",{id:"overview"},"Overview"),(0,l.kt)("p",null,"Jan's Model API aims to be as similar as possible to ",(0,l.kt)("a",{parentName:"p",href:"https://platform.openai.com/docs/api-reference/models"},"OpenAI's Models API"),", with additional methods for managing and running models locally. "),(0,l.kt)("h3",{id:"user-objectives"},"User Objectives"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Users can start/stop models and use them in a thread (or via Chat Completions API)"),(0,l.kt)("li",{parentName:"ul"},"Users can download, import and delete models  "),(0,l.kt)("li",{parentName:"ul"},"User can configure model settings at the model level or override it at thread-level"),(0,l.kt)("li",{parentName:"ul"},"Users can use remote models (e.g. OpenAI, OpenRouter)")),(0,l.kt)("h2",{id:"models-folder"},"Models Folder"),(0,l.kt)("p",null,"Models in Jan are stored in the ",(0,l.kt)("inlineCode",{parentName:"p"},"/models")," folder. "),(0,l.kt)("p",null," ",(0,l.kt)("inlineCode",{parentName:"p"},"<model-name>.json")," files. "),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Everything needed to represent a ",(0,l.kt)("inlineCode",{parentName:"li"},"model")," is packaged into an ",(0,l.kt)("inlineCode",{parentName:"li"},"Model folder"),"."),(0,l.kt)("li",{parentName:"ul"},"The ",(0,l.kt)("inlineCode",{parentName:"li"},"folder")," is standalone and can be easily zipped, imported, and exported, e.g. to Github."),(0,l.kt)("li",{parentName:"ul"},"The ",(0,l.kt)("inlineCode",{parentName:"li"},"folder")," always contains at least one ",(0,l.kt)("inlineCode",{parentName:"li"},"Model Object"),", declared in a ",(0,l.kt)("inlineCode",{parentName:"li"},"json")," format."),(0,l.kt)("li",{parentName:"ul"},"The ",(0,l.kt)("inlineCode",{parentName:"li"},"folder")," and ",(0,l.kt)("inlineCode",{parentName:"li"},"file")," do not have to share the same name"),(0,l.kt)("li",{parentName:"ul"},"The model ",(0,l.kt)("inlineCode",{parentName:"li"},"id")," is made up of ",(0,l.kt)("inlineCode",{parentName:"li"},"folder_name/filename")," and is thus always unique.")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sh"},"/janroot\n    /models\n        azure-openai/                       # Folder name\n            azure-openai-gpt3-5.json        # File name\n\n        llama2-70b/\n            model.json\n            .gguf\n")),(0,l.kt)("h2",{id:"model-object"},"Model Object"),(0,l.kt)("p",null,"Models in Jan are represented as ",(0,l.kt)("inlineCode",{parentName:"p"},"json")," objects, and are colloquially known as ",(0,l.kt)("inlineCode",{parentName:"p"},"model.jsons"),". "),(0,l.kt)("p",null,"Jan's models follow a ",(0,l.kt)("inlineCode",{parentName:"p"},"<model_name>.json")," naming convention. "),(0,l.kt)("p",null,"Jan's ",(0,l.kt)("inlineCode",{parentName:"p"},"model.json")," aims for rough equivalence with ",(0,l.kt)("a",{parentName:"p",href:"https://platform.openai.com/docs/api-reference/models/object"},"OpenAI's Model Object"),", and add additional properties to support local models.  "),(0,l.kt)("p",null,"Jan's ",(0,l.kt)("inlineCode",{parentName:"p"},"model.json")," object properties are optional, i.e. users should be able to run a model declared by an empty ",(0,l.kt)("inlineCode",{parentName:"p"},"json")," file."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-json"},'// ./models/zephr/zephyr-7b-beta-Q4_K_M.json\n{\n    "source_url": "https://huggingface.co/TheBloke/zephyr-7B-beta-GGUF/blob/main/zephyr-7b-beta.Q4_K_M.gguf",\n    "parameters": {\n        "init": {\n            "ctx_len": "2048",\n            "ngl": "100",\n            "embedding": "true",\n            "n_parallel": "4",\n            "pre_prompt": "A chat between a curious user and an artificial intelligence",\n            "user_prompt": "USER: ",\n            "ai_prompt": "ASSISTANT: "\n        },\n        "runtime": {\n            "temperature": "0.7",\n            "token_limit": "2048",\n            "top_k": "0",\n            "top_p": "1",\n            "stream": "true"\n        }\n    },\n    "metadata": {\n        "engine": "llamacpp",\n        "quantization": "Q4_K_M",\n        "size": "7B",\n    }\n}\n')),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Property"),(0,l.kt)("th",{parentName:"tr",align:null},"Type"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"),(0,l.kt)("th",{parentName:"tr",align:null},"Validation"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"object")),(0,l.kt)("td",{parentName:"tr",align:null},"enum: ",(0,l.kt)("inlineCode",{parentName:"td"},"model"),", ",(0,l.kt)("inlineCode",{parentName:"td"},"assistant"),", ",(0,l.kt)("inlineCode",{parentName:"td"},"thread"),", ",(0,l.kt)("inlineCode",{parentName:"td"},"message")),(0,l.kt)("td",{parentName:"tr",align:null},"Type of the Jan Object. Always ",(0,l.kt)("inlineCode",{parentName:"td"},"model")),(0,l.kt)("td",{parentName:"tr",align:null},'Defaults to "model"')),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"source_url")),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"The model download source. It can be an external url or a local filepath."),(0,l.kt)("td",{parentName:"tr",align:null},"Defaults to ",(0,l.kt)("inlineCode",{parentName:"td"},"pwd"),". See ",(0,l.kt)("a",{parentName:"td",href:"#Source_url"},"Source_url"))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"parameters")),(0,l.kt)("td",{parentName:"tr",align:null},"map"),(0,l.kt)("td",{parentName:"tr",align:null},"Defines default model run parameters used by any assistant."),(0,l.kt)("td",{parentName:"tr",align:null},"Defaults to ",(0,l.kt)("inlineCode",{parentName:"td"},"{}"))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"description")),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"A vanity description of the model"),(0,l.kt)("td",{parentName:"tr",align:null},'Defaults to ""')),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"metadata")),(0,l.kt)("td",{parentName:"tr",align:null},"map"),(0,l.kt)("td",{parentName:"tr",align:null},"Stores additional structured information about the model."),(0,l.kt)("td",{parentName:"tr",align:null},"Defaults to ",(0,l.kt)("inlineCode",{parentName:"td"},"{}"))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"metadata.engine")),(0,l.kt)("td",{parentName:"tr",align:null},"enum: ",(0,l.kt)("inlineCode",{parentName:"td"},"llamacpp"),", ",(0,l.kt)("inlineCode",{parentName:"td"},"api"),", ",(0,l.kt)("inlineCode",{parentName:"td"},"tensorrt")),(0,l.kt)("td",{parentName:"tr",align:null},"The model backend used to run model."),(0,l.kt)("td",{parentName:"tr",align:null},'Defaults to "llamacpp"')),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"metadata.quantization")),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"Supported formats only"),(0,l.kt)("td",{parentName:"tr",align:null},"See ",(0,l.kt)("a",{parentName:"td",href:"#Custom-importers"},"Custom importers"))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"metadata.binaries")),(0,l.kt)("td",{parentName:"tr",align:null},"array"),(0,l.kt)("td",{parentName:"tr",align:null},"Supported formats only."),(0,l.kt)("td",{parentName:"tr",align:null},"See ",(0,l.kt)("a",{parentName:"td",href:"#Custom-importers"},"Custom importers"))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"state")),(0,l.kt)("td",{parentName:"tr",align:null},"enum","[",(0,l.kt)("inlineCode",{parentName:"td"},"to_download")," , ",(0,l.kt)("inlineCode",{parentName:"td"},"downloading"),", ",(0,l.kt)("inlineCode",{parentName:"td"},"ready")," , ",(0,l.kt)("inlineCode",{parentName:"td"},"running"),"]"),(0,l.kt)("td",{parentName:"tr",align:null},"Needs more thought"),(0,l.kt)("td",{parentName:"tr",align:null},"Defaults to ",(0,l.kt)("inlineCode",{parentName:"td"},"to_download"))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"name")),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"A vanity name"),(0,l.kt)("td",{parentName:"tr",align:null},"Defaults to filename")))),(0,l.kt)("h3",{id:"model-source"},"Model Source"),(0,l.kt)("p",null,"There are 3 types of model sources"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Local model")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Remote source")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Cloud API")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Users can download models from a ",(0,l.kt)("inlineCode",{parentName:"p"},"remote")," source or reference an existing ",(0,l.kt)("inlineCode",{parentName:"p"},"local")," model.")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"If this property is not specified in the Model Object file, then the default behavior is to look in the current directory.")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Users can import a local model by providing the filepath to the model"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-json"},'// ./models/llama2/llama2-7bn-gguf.json\n"source_url": "~/Downloads/llama-2-7bn-q5-k-l.gguf",\n\n// Default, if property is omitted\n"source_url": "./",\n')),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Users can download a model by remote URL.")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Supported url formats:"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/blob/main/llama-2-7b-chat.Q3_K_L.gguf")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"https://any-source.com/.../model-binary.bin")))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Using a remote API to access model ",(0,l.kt)("inlineCode",{parentName:"p"},"model-azure-openai-gpt4-turbo.json"))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"See ",(0,l.kt)("a",{parentName:"p",href:"https://learn.microsoft.com/en-us/azure/ai-services/openai/quickstart?tabs=command-line%2Cpython&pivots=rest-api"},"source")))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-json"},'"source_url": "https://docs-test-001.openai.azure.com/openai.azure.com/docs-test-001/gpt4-turbo",\n"parameters": {\n  "init" {\n    "API-KEY": "",\n    "DEPLOYMENT-NAME": "",\n    "api-version": "2023-05-15"\n  },\n  "runtime": {\n    "temperature": "0.7",\n    "max_tokens": "2048",\n    "presence_penalty": "0",\n    "top_p": "1",\n    "stream": "true"\n  }\n}\n"metadata": {\n    "engine": "api",\n}\n')),(0,l.kt)("h3",{id:"model-formats"},"Model Formats"),(0,l.kt)("p",null,"Additionally, Jan supports importing popular formats. For example, if you provide a HuggingFace URL for a ",(0,l.kt)("inlineCode",{parentName:"p"},"TheBloke")," model, Jan automatically downloads and catalogs all quantizations. Custom importers autofills properties like ",(0,l.kt)("inlineCode",{parentName:"p"},"metadata.quantization")," and ",(0,l.kt)("inlineCode",{parentName:"p"},"metadata.size"),"."),(0,l.kt)("p",null,"Supported URL formats with custom importers:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"huggingface/thebloke"),": ",(0,l.kt)("a",{parentName:"li",href:"https://huggingface.co/TheBloke/Llama-2-7B-GGUF"},"Link")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"huggingface/thebloke"),": ",(0,l.kt)("a",{parentName:"li",href:"https://huggingface.co/TheBloke/Llama-2-7B-GGUF"},"Link")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"janhq"),": ",(0,l.kt)("inlineCode",{parentName:"li"},"TODO: put URL here")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"azure_openai"),": ",(0,l.kt)("inlineCode",{parentName:"li"},"https://docs-test-001.openai.azure.com/openai.azure.com/docs-test-001/gpt4-turbo")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"openai"),": ",(0,l.kt)("inlineCode",{parentName:"li"},"api.openai.com"))),(0,l.kt)("details",null,(0,l.kt)("summary",null,"Example: Zephyr 7B"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Model has 1 binary ",(0,l.kt)("inlineCode",{parentName:"li"},"model-zephyr-7B.json")),(0,l.kt)("li",{parentName:"ul"},"See ",(0,l.kt)("a",{parentName:"li",href:"https://huggingface.co/TheBloke/zephyr-7B-beta-GGUF/"},"source"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-json"},'// ./models/zephr/zephyr-7b-beta-Q4_K_M.json\n// Note: Default fields omitted for brevity\n"source_url": "https://huggingface.co/TheBloke/zephyr-7B-beta-GGUF/blob/main/zephyr-7b-beta.Q4_K_M.gguf",\n"parameters": {\n  "init": {\n    "ctx_len": "2048",\n    "ngl": "100",\n    "embedding": "true",\n    "n_parallel": "4",\n    "pre_prompt": "A chat between a curious user and an artificial intelligence",\n    "user_prompt": "USER: ",\n    "ai_prompt": "ASSISTANT: "\n  },\n  "runtime": {\n    "temperature": "0.7",\n    "token_limit": "2048",\n    "top_k": "0",\n    "top_p": "1",\n    "stream": "true"\n  }\n},\n"metadata": {\n    "engine": "llamacpp",\n    "quantization": "Q3_K_L",\n    "size": "7B",\n}\n'))),(0,l.kt)("h3",{id:"multiple-binaries"},"Multiple binaries"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Model has multiple binaries ",(0,l.kt)("inlineCode",{parentName:"li"},"model-llava-1.5-ggml.json")),(0,l.kt)("li",{parentName:"ul"},"See ",(0,l.kt)("a",{parentName:"li",href:"https://huggingface.co/mys/ggml_llava-v1.5-13b"},"source"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-json"},'"source_url": "https://huggingface.co/mys/ggml_llava-v1.5-13b",\n"parameters": {"init": {}, "runtime": {}}\n"metadata": {\n    "mmproj_binary": "https://huggingface.co/mys/ggml_llava-v1.5-13b/blob/main/mmproj-model-f16.gguf",\n    "ggml_binary": "https://huggingface.co/mys/ggml_llava-v1.5-13b/blob/main/ggml-model-q5_k.gguf",\n    "engine": "llamacpp",\n    "quantization": "Q5_K"\n}\n')),(0,l.kt)("h2",{id:"models-api"},"Models API"),(0,l.kt)("h3",{id:"get-model"},"Get Model"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"OpenAI Equivalent: ",(0,l.kt)("a",{parentName:"li",href:"https://platform.openai.com/docs/api-reference/models/retrieve"},"https://platform.openai.com/docs/api-reference/models/retrieve")),(0,l.kt)("li",{parentName:"ul"},"OpenAI Equivalent: ",(0,l.kt)("a",{parentName:"li",href:"https://platform.openai.com/docs/api-reference/models/object"},"https://platform.openai.com/docs/api-reference/models/object")),(0,l.kt)("li",{parentName:"ul"},"The ",(0,l.kt)("inlineCode",{parentName:"li"},"Jan Model Object")," maps into the ",(0,l.kt)("inlineCode",{parentName:"li"},"OpenAI Model Object"),"."),(0,l.kt)("li",{parentName:"ul"},"Properties marked with ",(0,l.kt)("inlineCode",{parentName:"li"},"*")," are compatible with the ",(0,l.kt)("a",{parentName:"li",href:"https://platform.openai.com/docs/api-reference/models"},"OpenAI ",(0,l.kt)("inlineCode",{parentName:"a"},"model")," object")),(0,l.kt)("li",{parentName:"ul"},"Note: The ",(0,l.kt)("inlineCode",{parentName:"li"},"Jan Model Object")," has additional properties when retrieved via its API endpoint.")),(0,l.kt)("h4",{id:"request"},"Request"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-shell"},"curl {JAN_URL}/v1/models/{model_id}\n")),(0,l.kt)("h4",{id:"response"},"Response"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "id": "model-zephyr-7B",\n  "object": "model",\n  "created_at": 1686935002,\n  "owned_by": "thebloke",\n  "state": "running",\n  "source_url": "https://huggingface.co/TheBloke/zephyr-7B-beta-GGUF/blob/main/zephyr-7b-beta.Q4_K_M.gguf",\n  "parameters": {\n     "ctx_len": 2048,\n     "ngl": 100,\n     "embedding": true,\n     "n_parallel": 4,\n     "pre_prompt": "A chat between a curious user and an artificial intelligence",\n     "user_prompt": "USER: ",\n     "ai_prompt": "ASSISTANT: ",\n     "temperature": "0.7",\n     "token_limit": "2048",\n     "top_k": "0",\n     "top_p": "1",\n  },\n  "metadata": {\n     "engine": "llamacpp",\n     "quantization": "Q3_K_L",\n     "size": "7B",\n  }\n}\n')),(0,l.kt)("h3",{id:"list-models"},"List models"),(0,l.kt)("p",null,"Lists the currently available models, and provides basic information about each one such as the owner and availability."),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},"OpenAI Equivalent: ",(0,l.kt)("a",{parentName:"p",href:"https://platform.openai.com/docs/api-reference/models/list"},"https://platform.openai.com/docs/api-reference/models/list"))),(0,l.kt)("h4",{id:"request-1"},"Request"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-shell="},"curl {JAN_URL}/v1/models\n")),(0,l.kt)("h4",{id:"response-1"},"Response"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "object": "list",\n  "data": [\n    {\n      "id": "model-zephyr-7B",\n      "object": "model",\n      "created_at": 1686935002,\n      "owned_by": "thebloke",\n      "state": "running"\n    },\n    {\n      "id": "ft-llama-70b-gguf",\n      "object": "model",\n      "created_at": 1686935002,\n      "owned_by": "you",\n      "state": "stopped"\n    },\n    {\n      "id": "model-azure-openai-gpt4-turbo",\n      "object": "model",\n      "created_at": 1686935002,\n      "owned_by": "azure_openai",\n      "state": "running"\n    },\n  ],\n  "object": "list"\n}\n')),(0,l.kt)("h3",{id:"delete-model"},"Delete Model"),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},"OpenAI Equivalent: ",(0,l.kt)("a",{parentName:"p",href:"https://platform.openai.com/docs/api-reference/models/delete"},"https://platform.openai.com/docs/api-reference/models/delete"))),(0,l.kt)("h4",{id:"request-2"},"Request"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-shell"},"curl -X DELETE {JAN_URL}/v1/models/{model_id}\n")),(0,l.kt)("h4",{id:"response-2"},"Response"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "id": "model-zephyr-7B",\n  "object": "model",\n  "deleted": true,\n  "state": "to_download"\n}\n')),(0,l.kt)("h3",{id:"start-model"},"Start Model"),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},"Jan-only endpoint\nThe request to start ",(0,l.kt)("inlineCode",{parentName:"p"},"model")," by changing model state from ",(0,l.kt)("inlineCode",{parentName:"p"},"ready")," to ",(0,l.kt)("inlineCode",{parentName:"p"},"running"))),(0,l.kt)("h4",{id:"request-3"},"Request"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-shell"},"curl -X PUT {JAN_URL}/v1/models{model_id}/start\n")),(0,l.kt)("h4",{id:"response-3"},"Response"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "id": "model-zephyr-7B",\n  "object": "model",\n  "state": "running"\n}\n')),(0,l.kt)("h3",{id:"stop-model"},"Stop Model"),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},"Jan-only endpoint\nThe request to start ",(0,l.kt)("inlineCode",{parentName:"p"},"model")," by changing model state from ",(0,l.kt)("inlineCode",{parentName:"p"},"running")," to ",(0,l.kt)("inlineCode",{parentName:"p"},"ready"))),(0,l.kt)("h4",{id:"request-4"},"Request"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-shell"},"curl -X PUT {JAN_URL}/v1/models/{model_id}/stop\n")),(0,l.kt)("h4",{id:"response-4"},"Response"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "id": "model-zephyr-7B",\n  "object": "model",\n  "state": "ready"\n}\n')),(0,l.kt)("h3",{id:"download-model"},"Download Model"),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},"Jan-only endpoint\nThe request to download ",(0,l.kt)("inlineCode",{parentName:"p"},"model")," by changing model state from ",(0,l.kt)("inlineCode",{parentName:"p"},"to_download")," to ",(0,l.kt)("inlineCode",{parentName:"p"},"downloading")," then ",(0,l.kt)("inlineCode",{parentName:"p"},"ready"),"once it's done.")),(0,l.kt)("h4",{id:"request-5"},"Request"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-shell"},"curl -X POST {JAN_URL}/v1/models/\n")),(0,l.kt)("h4",{id:"response-5"},"Response"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "id": "model-zephyr-7B",\n  "object": "model",\n  "state": "downloading"\n}\n')),(0,l.kt)("h2",{id:"examples"},"Examples"),(0,l.kt)("h3",{id:"pre-loaded-models"},"Pre-loaded Models"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Jan ships with a default model folders containing recommended models"),(0,l.kt)("li",{parentName:"ul"},"Only the Model Object ",(0,l.kt)("inlineCode",{parentName:"li"},"json")," files are included"),(0,l.kt)("li",{parentName:"ul"},"Users must later explicitly download the model binaries"),(0,l.kt)("li",{parentName:"ul"})),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sh"},"models/\n    mistral-7b/\n        mistral-7b.json\n    hermes-7b/\n        hermes-7b.json\n")),(0,l.kt)("h3",{id:"azure-openai"},"Azure OpenAI"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Using a remote API to access model ",(0,l.kt)("inlineCode",{parentName:"li"},"model-azure-openai-gpt4-turbo.json")),(0,l.kt)("li",{parentName:"ul"},"See ",(0,l.kt)("a",{parentName:"li",href:"https://learn.microsoft.com/en-us/azure/ai-services/openai/quickstart?tabs=command-line%2Cpython&pivots=rest-api"},"source"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-json"},'"source_url": "https://docs-test-001.openai.azure.com/openai.azure.com/docs-test-001/gpt4-turbo",\n"parameters": {\n  "init" {\n    "API-KEY": "",\n    "DEPLOYMENT-NAME": "",\n    "api-version": "2023-05-15"\n  },\n  "runtime": {\n    "temperature": "0.7",\n    "max_tokens": "2048",\n    "presence_penalty": "0",\n    "top_p": "1",\n    "stream": "true"\n  }\n}\n"metadata": {\n    "engine": "api",\n}\n')),(0,l.kt)("h3",{id:"multiple-quantizations"},"Multiple quantizations"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Each quantization has its own ",(0,l.kt)("inlineCode",{parentName:"li"},"Jan Model Object")," file")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sh"},"llama2-7b-gguf/\n    llama2-7b-gguf-Q2.json\n    llama2-7b-gguf-Q3_K_L.json\n    .bin\n")),(0,l.kt)("h3",{id:"multiple-model-partitions"},"Multiple model partitions"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"A Model that is partitioned into several binaries use just 1 file")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sh"},"llava-ggml/\n    llava-ggml-Q5.json\n    .proj\n    ggml\n")),(0,l.kt)("h3",{id:"your-locally-fine-tuned-model"},"Your locally fine-tuned model"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"??")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sh"},"llama-70b-finetune/\n    llama-70b-finetune-q5.json\n    .bin\n")))}u.isMDXComponent=!0}}]);