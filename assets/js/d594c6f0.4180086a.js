"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[574],{5820:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>o,default:()=>h,frontMatter:()=>i,metadata:()=>r,toc:()=>d});var a=t(85893),l=t(11151);const i={title:"Integrate Ollama with Jan",slug:"/guides/integrations/ollama",description:"Guide to integrate Ollama with Jan",keywords:["Jan AI","Jan","ChatGPT alternative","local AI","private AI","conversational AI","no-subscription fee","large language model","Ollama integration"]},o=void 0,r={id:"guides/integrations/integrate-ollama",title:"Integrate Ollama with Jan",description:"Guide to integrate Ollama with Jan",source:"@site/docs/guides/07-integrations/06-integrate-ollama.mdx",sourceDirName:"guides/07-integrations",slug:"/guides/integrations/ollama",permalink:"/guides/integrations/ollama",draft:!1,unlisted:!1,editUrl:"https://github.com/janhq/jan/tree/main/docs/docs/guides/07-integrations/06-integrate-ollama.mdx",tags:[],version:"current",lastUpdatedBy:"Henry",lastUpdatedAt:1708673495,formattedLastUpdatedAt:"Feb 23, 2024",sidebarPosition:6,frontMatter:{title:"Integrate Ollama with Jan",slug:"/guides/integrations/ollama",description:"Guide to integrate Ollama with Jan",keywords:["Jan AI","Jan","ChatGPT alternative","local AI","private AI","conversational AI","no-subscription fee","large language model","Ollama integration"]},sidebar:"guidesSidebar",previous:{title:"Integrate LM Studio with Jan",permalink:"/guides/integrations/lmstudio"},next:{title:"Troubleshooting",permalink:"/guides/troubleshooting/"}},s={},d=[{value:"Quick Introduction",id:"quick-introduction",level:2},{value:"Steps to Integrate Ollama Server with Jan UI",id:"steps-to-integrate-ollama-server-with-jan-ui",level:2},{value:"1. Start the Ollama Server",id:"1-start-the-ollama-server",level:3},{value:"2. Modify a Model JSON",id:"2-modify-a-model-json",level:3},{value:"3. Start the Model",id:"3-start-the-model",level:3},{value:"4. Try Out the Integration of Jan and Ollama",id:"4-try-out-the-integration-of-jan-and-ollama",level:3}];function c(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.a)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.h2,{id:"quick-introduction",children:"Quick Introduction"}),"\n",(0,a.jsxs)(n.p,{children:["With ",(0,a.jsx)(n.a,{href:"https://ollama.com/",children:"Ollama"}),", you can run large language models locally. In this guide, we will show you how to integrate and use your current models on Ollama with Jan using 2 methods.  The first method is integrating Ollama server with Jan UI. The second method is migrating your downloaded model from Ollama to Jan. We will use the ",(0,a.jsx)(n.a,{href:"https://ollama.com/library/llama2",children:"llama2"})," model as an example."]}),"\n",(0,a.jsx)(n.h2,{id:"steps-to-integrate-ollama-server-with-jan-ui",children:"Steps to Integrate Ollama Server with Jan UI"}),"\n",(0,a.jsx)(n.h3,{id:"1-start-the-ollama-server",children:"1. Start the Ollama Server"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["Select the model you want to use from the ",(0,a.jsx)(n.a,{href:"https://ollama.com/library",children:"Ollama library"}),"."]}),"\n",(0,a.jsx)(n.li,{children:"Run your model by using the following command:"}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"ollama run <model-name>\n"})}),"\n",(0,a.jsxs)(n.ol,{start:"3",children:["\n",(0,a.jsxs)(n.li,{children:["According to the ",(0,a.jsx)(n.a,{href:"https://github.com/ollama/ollama/blob/main/docs/openai.md",children:"Ollama documentation on OpenAI compatibility"}),", you can use the ",(0,a.jsx)(n.code,{children:"http://localhost:11434/v1/chat/completions"})," endpoint to interact with the Ollama server. Thus, modify the ",(0,a.jsx)(n.code,{children:"openai.json"})," file in the ",(0,a.jsx)(n.code,{children:"~/jan/engines"})," folder to include the full URL of the Ollama server."]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-json",metastring:'title="~/jan/engines/openai.json"',children:'{\n  "full_url": "http://localhost:11434/v1/chat/completions"\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"2-modify-a-model-json",children:"2. Modify a Model JSON"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["Navigate to the ",(0,a.jsx)(n.code,{children:"~/jan/models"})," folder."]}),"\n",(0,a.jsxs)(n.li,{children:["Create a folder named ",(0,a.jsx)(n.code,{children:"<ollam-modelname>"}),", for example, ",(0,a.jsx)(n.code,{children:"lmstudio-phi-2"}),"."]}),"\n",(0,a.jsxs)(n.li,{children:["Create a ",(0,a.jsx)(n.code,{children:"model.json"})," file inside the folder including the following configurations:"]}),"\n"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Set the ",(0,a.jsx)(n.code,{children:"id"})," property to the model name as Ollama model name."]}),"\n",(0,a.jsxs)(n.li,{children:["Set the ",(0,a.jsx)(n.code,{children:"format"})," property to ",(0,a.jsx)(n.code,{children:"api"}),"."]}),"\n",(0,a.jsxs)(n.li,{children:["Set the ",(0,a.jsx)(n.code,{children:"engine"})," property to ",(0,a.jsx)(n.code,{children:"openai"}),"."]}),"\n",(0,a.jsxs)(n.li,{children:["Set the ",(0,a.jsx)(n.code,{children:"state"})," property to ",(0,a.jsx)(n.code,{children:"ready"}),"."]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-json",metastring:'title="~/jan/models/llama2/model.json"',children:'{\n  "sources": [\n    {\n      "filename": "llama2",\n      "url": "https://ollama.com/library/llama2"\n    }\n  ],\n  // highlight-next-line\n  "id": "llama2",\n  "object": "model",\n  "name": "Ollama - Llama2",\n  "version": "1.0",\n  "description": "Llama 2 is a collection of foundation language models ranging from 7B to 70B parameters.",\n  // highlight-next-line\n  "format": "api",\n  "settings": {},\n  "parameters": {},\n  "metadata": {\n    "author": "Meta",\n    "tags": ["General", "Big Context Length"]\n  },\n  // highlight-next-line\n  "engine": "openai"\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"3-start-the-model",children:"3. Start the Model"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["Restart Jan and navigate to the ",(0,a.jsx)(n.strong,{children:"Hub"}),"."]}),"\n",(0,a.jsxs)(n.li,{children:["Locate your model and click the ",(0,a.jsx)(n.strong,{children:"Use"})," button."]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Ollama Model",src:t(38222).Z+"",width:"3456",height:"2152"})}),"\n",(0,a.jsx)(n.h3,{id:"4-try-out-the-integration-of-jan-and-ollama",children:"4. Try Out the Integration of Jan and Ollama"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Ollama Integration Demo",src:t(78164).Z+"",width:"1036",height:"720"})})]})}function h(e={}){const{wrapper:n}={...(0,l.a)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},78164:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/06-ollama-integration-demo-527bcdff1493584ffa09c54058f1afb6.gif"},38222:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/06-ollama-run-158f5c0dc48b5b7fd388c8c5d5f56ccc.png"},11151:(e,n,t)=>{t.d(n,{Z:()=>r,a:()=>o});var a=t(67294);const l={},i=a.createContext(l);function o(e){const n=a.useContext(i);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:o(e.components),a.createElement(i.Provider,{value:n},e.children)}}}]);