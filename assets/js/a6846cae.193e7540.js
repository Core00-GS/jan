"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5585],{81775:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>r,metadata:()=>a,toc:()=>c});var t=i(85893),s=i(11151);const r={title:"Docker",slug:"/install/docker",description:"Jan is a ChatGPT-alternative that runs on your own computer, with a local API server.",keywords:["Jan AI","Jan","ChatGPT alternative","local AI","private AI","conversational AI","no-subscription fee","large language model","docker installation"]},o="Installing Jan using Docker",a={id:"guides/installation/docker",title:"Docker",description:"Jan is a ChatGPT-alternative that runs on your own computer, with a local API server.",source:"@site/docs/guides/02-installation/05-docker.md",sourceDirName:"guides/02-installation",slug:"/install/docker",permalink:"/install/docker",draft:!1,unlisted:!1,editUrl:"https://github.com/janhq/jan/tree/main/docs/docs/guides/02-installation/05-docker.md",tags:[],version:"current",lastUpdatedBy:"Henry",lastUpdatedAt:1708673495,formattedLastUpdatedAt:"Feb 23, 2024",sidebarPosition:5,frontMatter:{title:"Docker",slug:"/install/docker",description:"Jan is a ChatGPT-alternative that runs on your own computer, with a local API server.",keywords:["Jan AI","Jan","ChatGPT alternative","local AI","private AI","conversational AI","no-subscription fee","large language model","docker installation"]},sidebar:"guidesSidebar",previous:{title:"From Source",permalink:"/install/from-source"},next:{title:"Hardware Requirements",permalink:"/guides/install/hardware"}},l={},c=[{value:"Installation",id:"installation",level:2},{value:"Pre-requisites",id:"pre-requisites",level:3},{value:"Instructions",id:"instructions",level:3}];function d(n){const e={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.a)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.h1,{id:"installing-jan-using-docker",children:"Installing Jan using Docker"}),"\n",(0,t.jsx)(e.h2,{id:"installation",children:"Installation"}),"\n",(0,t.jsx)(e.h3,{id:"pre-requisites",children:"Pre-requisites"}),"\n",(0,t.jsx)(e.admonition,{type:"note",children:(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Supported OS"}),": Linux, WSL2 Docker"]})}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["Docker Engine and Docker Compose are required to run Jan in Docker mode. Follow the ",(0,t.jsx)(e.a,{href:"https://docs.docker.com/engine/install/ubuntu/",children:"instructions"})," below to get started with Docker Engine on Ubuntu."]}),"\n"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"curl -fsSL https://get.docker.com -o get-docker.sh\nsudo sh ./get-docker.sh --dry-run\n"})}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["If you intend to run Jan in GPU mode, you need to install ",(0,t.jsx)(e.code,{children:"nvidia-driver"})," and ",(0,t.jsx)(e.code,{children:"nvidia-docker2"}),". Follow the instruction ",(0,t.jsx)(e.a,{href:"https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html",children:"here"})," for installation."]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"instructions",children:"Instructions"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Run Jan in Docker mode"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Option 1"}),": Run Jan in CPU mode"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"docker compose --profile cpu up -d\n"})}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Option 2"}),": Run Jan in GPU mode"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Step 1"}),": Check CUDA compatibility with your NVIDIA driver by running ",(0,t.jsx)(e.code,{children:"nvidia-smi"})," and check the CUDA version in the output"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"nvidia-smi\n\n# Output\n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 531.18                 Driver Version: 531.18       CUDA Version: 12.1     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA GeForce RTX 4070 Ti    WDDM | 00000000:01:00.0  On |                  N/A |\n|  0%   44C    P8               16W / 285W|   1481MiB / 12282MiB |      2%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n|   1  NVIDIA GeForce GTX 1660 Ti    WDDM | 00000000:02:00.0 Off |                  N/A |\n|  0%   49C    P8               14W / 120W|      0MiB /  6144MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n|   2  NVIDIA GeForce GTX 1660 Ti    WDDM | 00000000:05:00.0 Off |                  N/A |\n| 29%   38C    P8               11W / 120W|      0MiB /  6144MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n\n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n"})}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Step 2"}),": Visit ",(0,t.jsx)(e.a,{href:"https://catalog.ngc.nvidia.com/orgs/nvidia/containers/cuda/tags",children:"NVIDIA NGC Catalog "})," and find the smallest minor version of image tag that matches your CUDA version (e.g., 12.1 -> 12.1.0)"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Step 3"}),": Update the ",(0,t.jsx)(e.code,{children:"Dockerfile.gpu"})," line number 5 with the latest minor version of the image tag from step 2 (e.g. change ",(0,t.jsx)(e.code,{children:"FROM nvidia/cuda:12.2.0-runtime-ubuntu22.04 AS base"})," to ",(0,t.jsx)(e.code,{children:"FROM nvidia/cuda:12.1.0-runtime-ubuntu22.04 AS base"}),")"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Step 4"}),": Run command to start Jan in GPU mode"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# GPU mode\ndocker compose --profile gpu up -d\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:["This will start the web server and you can access Jan at ",(0,t.jsx)(e.code,{children:"http://localhost:3000"}),"."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.admonition,{type:"warning",children:(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Docker mode is currently only suitable for development and localhost. Production is not supported yet, and the RAG feature is not available in Docker mode."}),"\n"]})})]})}function u(n={}){const{wrapper:e}={...(0,s.a)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},11151:(n,e,i)=>{i.d(e,{Z:()=>a,a:()=>o});var t=i(67294);const s={},r=t.createContext(s);function o(n){const e=t.useContext(r);return t.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:o(n.components),t.createElement(r.Provider,{value:e},n.children)}}}]);