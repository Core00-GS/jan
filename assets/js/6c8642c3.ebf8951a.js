"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4239],{3905:(e,t,a)=>{a.d(t,{Zo:()=>u,kt:()=>k});var n=a(7294);function s(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){s(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,s=function(e,t){if(null==e)return{};var a,n,s={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(s[a]=e[a]);return s}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(s[a]=e[a])}return s}var i=n.createContext({}),d=function(e){var t=n.useContext(i),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},u=function(e){var t=d(e.components);return n.createElement(i.Provider,{value:t},e.children)},p="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},c=n.forwardRef((function(e,t){var a=e.components,s=e.mdxType,l=e.originalType,i=e.parentName,u=o(e,["components","mdxType","originalType","parentName"]),p=d(a),c=s,k=p["".concat(i,".").concat(c)]||p[c]||m[c]||l;return a?n.createElement(k,r(r({ref:t},u),{},{components:a})):n.createElement(k,r({ref:t},u))}));function k(e,t){var a=arguments,s=t&&t.mdxType;if("string"==typeof e||s){var l=a.length,r=new Array(l);r[0]=c;var o={};for(var i in t)hasOwnProperty.call(t,i)&&(o[i]=t[i]);o.originalType=e,o[p]="string"==typeof e?e:s,r[1]=o;for(var d=2;d<l;d++)r[d]=a[d];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}c.displayName="MDXCreateElement"},1825:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>i,contentTitle:()=>r,default:()=>m,frontMatter:()=>l,metadata:()=>o,toc:()=>d});var n=a(7462),s=(a(7294),a(3905));const l={title:"Introduction",slug:"/docs"},r=void 0,o={unversionedId:"docs/introduction",id:"docs/introduction",title:"Introduction",description:"Jan can be used to build a variety of AI use cases, at every level of the stack:",source:"@site/docs/docs/01_introduction.md",sourceDirName:"docs",slug:"/docs",permalink:"/docs",draft:!1,editUrl:"https://github.com/janhq/jan/tree/main/docs/docs/docs/01_introduction.md",tags:[],version:"current",lastUpdatedBy:"Faisal Amir",lastUpdatedAt:1699887813,formattedLastUpdatedAt:"Nov 13, 2023",sidebarPosition:1,frontMatter:{title:"Introduction",slug:"/docs"},sidebar:"docsSidebar",next:{title:"Quickstart",permalink:"/docs/quickstart"}},i={},d=[{value:"Resources",id:"resources",level:2},{value:"Key Concepts",id:"key-concepts",level:2},{value:"Modules",id:"modules",level:3},{value:"Local Filesystem",id:"local-filesystem",level:3},{value:"Jan: a &quot;global&quot; assistant",id:"jan-a-global-assistant",level:3}],u={toc:d},p="wrapper";function m(e){let{components:t,...a}=e;return(0,s.kt)(p,(0,n.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,s.kt)("p",null,"Jan can be used to build a variety of AI use cases, at every level of the stack:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"An OpenAI compatible API, with feature parity for ",(0,s.kt)("inlineCode",{parentName:"li"},"models"),", ",(0,s.kt)("inlineCode",{parentName:"li"},"assistants"),", ",(0,s.kt)("inlineCode",{parentName:"li"},"files")," and more"),(0,s.kt)("li",{parentName:"ul"},"A standard data format on top of the user's local filesystem, allowing for transparency and composability"),(0,s.kt)("li",{parentName:"ul"},"Automatically package and distribute to Mac, Windows and Linux. Cloud coming soon"),(0,s.kt)("li",{parentName:"ul"},"An UI kit to customize user interactions with ",(0,s.kt)("inlineCode",{parentName:"li"},"assistants")," and more"),(0,s.kt)("li",{parentName:"ul"},"A standalone inference engine for low level use cases")),(0,s.kt)("h2",{id:"resources"},"Resources"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"Create an AI assistant"),(0,s.kt)("li",{parentName:"ul"},"Run an OpenAI compatible API endpoint"),(0,s.kt)("li",{parentName:"ul"},"Build a VSCode plugin with a local model"),(0,s.kt)("li",{parentName:"ul"},"Build a Jan platform module")),(0,s.kt)("h2",{id:"key-concepts"},"Key Concepts"),(0,s.kt)("h3",{id:"modules"},"Modules"),(0,s.kt)("p",null,"Jan is comprised of system-level modules that mirror OpenAI\u2019s, exposing similar APIs and objects"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"Modules are modular, atomic implementations of a single OpenAI-compatible endpoint"),(0,s.kt)("li",{parentName:"ul"},"Modules can be swapped out for alternate implementations",(0,s.kt)("ul",{parentName:"li"},(0,s.kt)("li",{parentName:"ul"},"The default ",(0,s.kt)("inlineCode",{parentName:"li"},"messages")," module persists messages in thread-specific ",(0,s.kt)("inlineCode",{parentName:"li"},".json")),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("inlineCode",{parentName:"li"},"messages-postgresql")," uses Postgres for production-grade cloud-native environments")))),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:null},"Jan Module"),(0,s.kt)("th",{parentName:"tr",align:null},"Description"),(0,s.kt)("th",{parentName:"tr",align:null},"API Docs"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"Chat"),(0,s.kt)("td",{parentName:"tr",align:null},"Inference"),(0,s.kt)("td",{parentName:"tr",align:null},(0,s.kt)("a",{parentName:"td",href:"/api/chat"},"/chat"))),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"Models"),(0,s.kt)("td",{parentName:"tr",align:null},"Models"),(0,s.kt)("td",{parentName:"tr",align:null},(0,s.kt)("a",{parentName:"td",href:"/api/model"},"/model"))),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"Assistants"),(0,s.kt)("td",{parentName:"tr",align:null},"Apps"),(0,s.kt)("td",{parentName:"tr",align:null},(0,s.kt)("a",{parentName:"td",href:"/api/assistant"},"/assistant"))),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"Threads"),(0,s.kt)("td",{parentName:"tr",align:null},"Conversations"),(0,s.kt)("td",{parentName:"tr",align:null},(0,s.kt)("a",{parentName:"td",href:"/api/thread"},"/thread"))),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"Messages"),(0,s.kt)("td",{parentName:"tr",align:null},"Messages"),(0,s.kt)("td",{parentName:"tr",align:null},(0,s.kt)("a",{parentName:"td",href:"/api/message"},"/message"))))),(0,s.kt)("h3",{id:"local-filesystem"},"Local Filesystem"),(0,s.kt)("p",null,"Jan use the local filesystem for data persistence, similar to VSCode. This allows for composability and tinkerability."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sh="},"/janroot               # Jan's root folder (e.g. ~/jan)\n    /models            # For raw AI models\n    /threads           # For conversation history\n    /assistants        # For AI assistants' configs, knowledge, etc.\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sh="},"/models\n    /modelA\n        model.json        # Default model settings\n        llama-7b-q4.gguf  # Model binaries\n        llama-7b-q5.gguf  # Include different quantizations\n/threads\n    /jan-unixstamp-salt\n        model.json        # Overrides assistant/model-level model settings\n        thread.json       # thread metadata (e.g. subject)\n        messages.json     # messages\n        content.json      # What is this?\n        files/            # Future for RAG\n/assistants\n    /jan\n        assistant.json    # Assistant configs (see below)\n\n        # For any custom code\n        package.json      # Import npm modules\n                          # e.g. Langchain, Llamaindex\n        /src              # Supporting files (needs better name)\n            index.js      # Entrypoint\n            process.js    # For electron IPC processes (needs better name)\n\n        # `/threads` at root level\n        # `/models` at root level\n    /shakespeare\n        assistant.json\n        model.json        # Creator chooses model and settings\n        package.json\n        /src\n            index.js\n            process.js\n\n        /threads          # Assistants remember conversations in the future\n        /models           # Users can upload custom models\n            /finetuned-model\n")),(0,s.kt)("h3",{id:"jan-a-global-assistant"},'Jan: a "global" assistant'),(0,s.kt)("p",null,'Jan ships with a default assistant "Jan" that lets users chat with any open source model out-of-the-box.'),(0,s.kt)("p",null,"This assistant is defined in ",(0,s.kt)("inlineCode",{parentName:"p"},"/jan"),". It is a generic assistant to illustrate power of Jan. In the future, it will support additional features e.g. multi-assistant conversations"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},'Your Assistant "Jan" lets you pick any model that is in the root /models folder'),(0,s.kt)("li",{parentName:"ul"},"Right panel: pick LLM model and set model parameters"),(0,s.kt)("li",{parentName:"ul"},"Jan\u2019s threads will be at root level"),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("inlineCode",{parentName:"li"},"model.json")," will reflect model chosen for that session"),(0,s.kt)("li",{parentName:"ul"},"Be able to \u201cadd\u201d other assistants in the future"),(0,s.kt)("li",{parentName:"ul"},"Jan\u2019s files will be at thread level"),(0,s.kt)("li",{parentName:"ul"},"Jan is not a persistent memory assistant")))}m.isMDXComponent=!0}}]);