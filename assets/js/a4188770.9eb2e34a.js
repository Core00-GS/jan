"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[3316],{3905:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>k});var n=a(7294);function l(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){l(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,l=function(e,t){if(null==e)return{};var a,n,l={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(l[a]=e[a]);return l}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(l[a]=e[a])}return l}var p=n.createContext({}),m=function(e){var t=n.useContext(p),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},d=function(e){var t=m(e.components);return n.createElement(p.Provider,{value:t},e.children)},u="mdxType",s={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},c=n.forwardRef((function(e,t){var a=e.components,l=e.mdxType,r=e.originalType,p=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),u=m(a),c=l,k=u["".concat(p,".").concat(c)]||u[c]||s[c]||r;return a?n.createElement(k,o(o({ref:t},d),{},{components:a})):n.createElement(k,o({ref:t},d))}));function k(e,t){var a=arguments,l=t&&t.mdxType;if("string"==typeof e||l){var r=a.length,o=new Array(r);o[0]=c;var i={};for(var p in t)hasOwnProperty.call(t,p)&&(i[p]=t[p]);i.originalType=e,i[u]="string"==typeof e?e:l,o[1]=i;for(var m=2;m<r;m++)o[m]=a[m];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}c.displayName="MDXCreateElement"},267:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>o,default:()=>s,frontMatter:()=>r,metadata:()=>i,toc:()=>m});var n=a(7462),l=(a(7294),a(3905));const r={title:"Models"},o=void 0,i={unversionedId:"specs/models",id:"specs/models",title:"Models",description:"Draft Specification: functionality has not been implemented yet.",source:"@site/docs/specs/models.md",sourceDirName:"specs",slug:"/specs/models",permalink:"/specs/models",draft:!1,editUrl:"https://github.com/janhq/jan/tree/main/docs/docs/specs/models.md",tags:[],version:"current",lastUpdatedBy:"Hieu",lastUpdatedAt:1700364181,formattedLastUpdatedAt:"Nov 19, 2023",frontMatter:{title:"Models"},sidebar:"docsSidebar",previous:{title:"Chats",permalink:"/specs/chats"},next:{title:"Threads",permalink:"/specs/threads"}},p={},m=[{value:"User Stories",id:"user-stories",level:2},{value:"Jan Model Object",id:"jan-model-object",level:2},{value:"Source_url",id:"source_url",level:3},{value:"Local source_url",id:"local-source_url",level:4},{value:"Remote source_url",id:"remote-source_url",level:4},{value:"Custom importers",id:"custom-importers",level:4},{value:"Generic Example",id:"generic-example",level:3},{value:"Example: multiple binaries",id:"example-multiple-binaries",level:3},{value:"Example: Azure API",id:"example-azure-api",level:3},{value:"Filesystem",id:"filesystem",level:2},{value:"Default ./model folder",id:"default-model-folder",level:3},{value:"Multiple quantizations",id:"multiple-quantizations",level:3},{value:"Multiple model partitions",id:"multiple-model-partitions",level:3},{value:"Your locally fine-tuned model",id:"your-locally-fine-tuned-model",level:3},{value:"Jan API",id:"jan-api",level:2},{value:"Model API Object",id:"model-api-object",level:3},{value:"Model lifecycle",id:"model-lifecycle",level:3},{value:"Get Model",id:"get-model",level:3}],d={toc:m},u="wrapper";function s(e){let{components:t,...a}=e;return(0,l.kt)(u,(0,n.Z)({},d,a,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("admonition",{type:"warning"},(0,l.kt)("p",{parentName:"admonition"},"Draft Specification: functionality has not been implemented yet. "),(0,l.kt)("p",{parentName:"admonition"},"Feedback: ",(0,l.kt)("a",{parentName:"p",href:"https://hackmd.io/ulO3uB1AQCqLa5SAAMFOQw"},"HackMD: Models Spec")," ")),(0,l.kt)("p",null,"Models are AI models like Llama and Mistral"),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},"OpenAI Equivalent: ",(0,l.kt)("a",{parentName:"p",href:"https://platform.openai.com/docs/api-reference/models"},"https://platform.openai.com/docs/api-reference/models"))),(0,l.kt)("h2",{id:"user-stories"},"User Stories"),(0,l.kt)("p",null,(0,l.kt)("em",{parentName:"p"},"Users can download a model via a web URL")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Wireframes here")),(0,l.kt)("p",null,(0,l.kt)("em",{parentName:"p"},"Users can import a model from local directory")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Wireframes here")),(0,l.kt)("p",null,(0,l.kt)("em",{parentName:"p"},"Users can configure model settings, like run parameters")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Wireframes here")),(0,l.kt)("p",null,(0,l.kt)("em",{parentName:"p"},"Users can override run settings at runtime")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"See Assistant Spec and Thread")),(0,l.kt)("h2",{id:"jan-model-object"},"Jan Model Object"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"A ",(0,l.kt)("inlineCode",{parentName:"li"},"Jan Model Object"),' is a \u201crepresentation" of a model'),(0,l.kt)("li",{parentName:"ul"},"Objects are defined by ",(0,l.kt)("inlineCode",{parentName:"li"},"model-name.json")," files in ",(0,l.kt)("inlineCode",{parentName:"li"},"json")," format"),(0,l.kt)("li",{parentName:"ul"},"Objects are identified by ",(0,l.kt)("inlineCode",{parentName:"li"},"folder-name/model-name"),", where its ",(0,l.kt)("inlineCode",{parentName:"li"},"id")," is indicative of its file location."),(0,l.kt)("li",{parentName:"ul"},"Objects are designed to be compatible with ",(0,l.kt)("inlineCode",{parentName:"li"},"OpenAI Model Objects"),", with additional properties needed to run on our infrastructure."),(0,l.kt)("li",{parentName:"ul"},"ALL object properties are optional, i.e. users should be able to run a model declared by an empty ",(0,l.kt)("inlineCode",{parentName:"li"},"json")," file.")),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Property"),(0,l.kt)("th",{parentName:"tr",align:null},"Type"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"),(0,l.kt)("th",{parentName:"tr",align:null},"Validation"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"source_url")),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"The model download source. It can be an external url or a local filepath."),(0,l.kt)("td",{parentName:"tr",align:null},"Defaults to ",(0,l.kt)("inlineCode",{parentName:"td"},"pwd"),". See ",(0,l.kt)("a",{parentName:"td",href:"#Source_url"},"Source_url"))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"object")),(0,l.kt)("td",{parentName:"tr",align:null},"enum: ",(0,l.kt)("inlineCode",{parentName:"td"},"model"),", ",(0,l.kt)("inlineCode",{parentName:"td"},"assistant"),", ",(0,l.kt)("inlineCode",{parentName:"td"},"thread"),", ",(0,l.kt)("inlineCode",{parentName:"td"},"message")),(0,l.kt)("td",{parentName:"tr",align:null},"Type of the Jan Object. Always ",(0,l.kt)("inlineCode",{parentName:"td"},"model")),(0,l.kt)("td",{parentName:"tr",align:null},'Defaults to "model"')),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"name")),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"A vanity name"),(0,l.kt)("td",{parentName:"tr",align:null},"Defaults to filename")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"description")),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"A vanity description of the model"),(0,l.kt)("td",{parentName:"tr",align:null},'Defaults to ""')),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"state")),(0,l.kt)("td",{parentName:"tr",align:null},"enum","[",(0,l.kt)("inlineCode",{parentName:"td"},"to_download")," , ",(0,l.kt)("inlineCode",{parentName:"td"},"downloading"),", ",(0,l.kt)("inlineCode",{parentName:"td"},"ready")," , ",(0,l.kt)("inlineCode",{parentName:"td"},"running"),"]"),(0,l.kt)("td",{parentName:"tr",align:null},"Needs more thought"),(0,l.kt)("td",{parentName:"tr",align:null},"Defaults to ",(0,l.kt)("inlineCode",{parentName:"td"},"to_download"))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"parameters")),(0,l.kt)("td",{parentName:"tr",align:null},"map"),(0,l.kt)("td",{parentName:"tr",align:null},"Defines default model run parameters used by any assistant."),(0,l.kt)("td",{parentName:"tr",align:null},"Defaults to ",(0,l.kt)("inlineCode",{parentName:"td"},"{}"))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"metadata")),(0,l.kt)("td",{parentName:"tr",align:null},"map"),(0,l.kt)("td",{parentName:"tr",align:null},"Stores additional structured information about the model."),(0,l.kt)("td",{parentName:"tr",align:null},"Defaults to ",(0,l.kt)("inlineCode",{parentName:"td"},"{}"))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"metadata.engine")),(0,l.kt)("td",{parentName:"tr",align:null},"enum: ",(0,l.kt)("inlineCode",{parentName:"td"},"llamacpp"),", ",(0,l.kt)("inlineCode",{parentName:"td"},"api"),", ",(0,l.kt)("inlineCode",{parentName:"td"},"tensorrt")),(0,l.kt)("td",{parentName:"tr",align:null},"The model backend used to run model."),(0,l.kt)("td",{parentName:"tr",align:null},'Defaults to "llamacpp"')),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"metadata.quantization")),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"Supported formats only"),(0,l.kt)("td",{parentName:"tr",align:null},"See ",(0,l.kt)("a",{parentName:"td",href:"#Custom-importers"},"Custom importers"))),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"metadata.binaries")),(0,l.kt)("td",{parentName:"tr",align:null},"array"),(0,l.kt)("td",{parentName:"tr",align:null},"Supported formats only."),(0,l.kt)("td",{parentName:"tr",align:null},"See ",(0,l.kt)("a",{parentName:"td",href:"#Custom-importers"},"Custom importers"))))),(0,l.kt)("h3",{id:"source_url"},"Source_url"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Users can download models from a ",(0,l.kt)("inlineCode",{parentName:"li"},"remote")," source or reference an existing ",(0,l.kt)("inlineCode",{parentName:"li"},"local")," model."),(0,l.kt)("li",{parentName:"ul"},"If this property is not specified in the Model Object file, then the default behavior is to look in the current directory.")),(0,l.kt)("h4",{id:"local-source_url"},"Local source_url"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Users can import a local model by providing the filepath to the model")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-json"},'// ./models/llama2/llama2-7bn-gguf.json\n"source_url": "~/Downloads/llama-2-7bn-q5-k-l.gguf",\n\n// Default, if property is omitted\n"source_url": "./",\n')),(0,l.kt)("h4",{id:"remote-source_url"},"Remote source_url"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Users can download a model by remote URL."),(0,l.kt)("li",{parentName:"ul"},"Supported url formats:",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/blob/main/llama-2-7b-chat.Q3_K_L.gguf")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"https://any-source.com/.../model-binary.bin"))))),(0,l.kt)("h4",{id:"custom-importers"},"Custom importers"),(0,l.kt)("p",null,"Additionally, Jan supports importing popular formats. For example, if you provide a HuggingFace URL for a ",(0,l.kt)("inlineCode",{parentName:"p"},"TheBloke")," model, Jan automatically downloads and catalogs all quantizations. Custom importers autofills properties like ",(0,l.kt)("inlineCode",{parentName:"p"},"metadata.quantization")," and ",(0,l.kt)("inlineCode",{parentName:"p"},"metadata.size"),"."),(0,l.kt)("p",null,"Supported URL formats with custom importers:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"huggingface/thebloke"),": ",(0,l.kt)("a",{parentName:"li",href:"https://huggingface.co/TheBloke/Llama-2-7B-GGUF"},"Link")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"huggingface/thebloke"),": ",(0,l.kt)("a",{parentName:"li",href:"https://huggingface.co/TheBloke/Llama-2-7B-GGUF"},"Link")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"janhq"),": ",(0,l.kt)("inlineCode",{parentName:"li"},"TODO: put URL here")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"azure_openai"),": ",(0,l.kt)("inlineCode",{parentName:"li"},"https://docs-test-001.openai.azure.com/openai.azure.com/docs-test-001/gpt4-turbo")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"openai"),": ",(0,l.kt)("inlineCode",{parentName:"li"},"api.openai.com"))),(0,l.kt)("h3",{id:"generic-example"},"Generic Example"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Model has 1 binary ",(0,l.kt)("inlineCode",{parentName:"li"},"model-zephyr-7B.json")),(0,l.kt)("li",{parentName:"ul"},"See ",(0,l.kt)("a",{parentName:"li",href:"https://huggingface.co/TheBloke/zephyr-7B-beta-GGUF/"},"source"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-json"},'// ./models/zephr/zephyr-7b-beta-Q4_K_M.json\n// Note: Default fields omitted for brevity\n"source_url": "https://huggingface.co/TheBloke/zephyr-7B-beta-GGUF/blob/main/zephyr-7b-beta.Q4_K_M.gguf",\n"parameters": {\n  "init": {\n    "ctx_len": "2048",\n    "ngl": "100",\n    "embedding": "true",\n    "n_parallel": "4",\n    "pre_prompt": "A chat between a curious user and an artificial intelligence",\n    "user_prompt": "USER: ",\n    "ai_prompt": "ASSISTANT: "\n  },\n  "runtime": {\n    "temperature": "0.7",\n    "token_limit": "2048",\n    "top_k": "0",\n    "top_p": "1",\n    "stream": "true"\n  }\n},\n"metadata": {\n    "engine": "llamacpp",\n    "quantization": "Q3_K_L",\n    "size": "7B",\n}\n')),(0,l.kt)("h3",{id:"example-multiple-binaries"},"Example: multiple binaries"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Model has multiple binaries ",(0,l.kt)("inlineCode",{parentName:"li"},"model-llava-1.5-ggml.json")),(0,l.kt)("li",{parentName:"ul"},"See ",(0,l.kt)("a",{parentName:"li",href:"https://huggingface.co/mys/ggml_llava-v1.5-13b"},"source"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-json"},'"source_url": "https://huggingface.co/mys/ggml_llava-v1.5-13b",\n"parameters": {"init": {}, "runtime": {}}\n"metadata": {\n    "mmproj_binary": "https://huggingface.co/mys/ggml_llava-v1.5-13b/blob/main/mmproj-model-f16.gguf",\n    "ggml_binary": "https://huggingface.co/mys/ggml_llava-v1.5-13b/blob/main/ggml-model-q5_k.gguf",\n    "engine": "llamacpp",\n    "quantization": "Q5_K"\n}\n')),(0,l.kt)("h3",{id:"example-azure-api"},"Example: Azure API"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Using a remote API to access model ",(0,l.kt)("inlineCode",{parentName:"li"},"model-azure-openai-gpt4-turbo.json")),(0,l.kt)("li",{parentName:"ul"},"See ",(0,l.kt)("a",{parentName:"li",href:"https://learn.microsoft.com/en-us/azure/ai-services/openai/quickstart?tabs=command-line%2Cpython&pivots=rest-api"},"source"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-json"},'"source_url": "https://docs-test-001.openai.azure.com/openai.azure.com/docs-test-001/gpt4-turbo",\n"parameters": {\n  "init" {\n    "API-KEY": "",\n    "DEPLOYMENT-NAME": "",\n    "api-version": "2023-05-15"\n  },\n  "runtime": {\n    "temperature": "0.7",\n    "max_tokens": "2048",\n    "presence_penalty": "0",\n    "top_p": "1",\n    "stream": "true"\n  }\n}\n"metadata": {\n    "engine": "api",\n}\n')),(0,l.kt)("h2",{id:"filesystem"},"Filesystem"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Everything needed to represent a ",(0,l.kt)("inlineCode",{parentName:"li"},"model")," is packaged into an ",(0,l.kt)("inlineCode",{parentName:"li"},"Model folder"),"."),(0,l.kt)("li",{parentName:"ul"},"The ",(0,l.kt)("inlineCode",{parentName:"li"},"folder")," is standalone and can be easily zipped, imported, and exported, e.g. to Github."),(0,l.kt)("li",{parentName:"ul"},"The ",(0,l.kt)("inlineCode",{parentName:"li"},"folder")," always contains at least one ",(0,l.kt)("inlineCode",{parentName:"li"},"Model Object"),", declared in a ",(0,l.kt)("inlineCode",{parentName:"li"},"json")," format."),(0,l.kt)("li",{parentName:"ul"},"The ",(0,l.kt)("inlineCode",{parentName:"li"},"folder")," and ",(0,l.kt)("inlineCode",{parentName:"li"},"file")," do not have to share the same name"),(0,l.kt)("li",{parentName:"ul"},"The model ",(0,l.kt)("inlineCode",{parentName:"li"},"id")," is made up of ",(0,l.kt)("inlineCode",{parentName:"li"},"folder_name/filename")," and is thus always unique.")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sh"},"/janroot\n    /models\n        azure-openai/                       # Folder name\n            azure-openai-gpt3-5.json        # File name\n\n        llama2-70b/\n            model.json\n            .gguf\n")),(0,l.kt)("h3",{id:"default-model-folder"},"Default ./model folder"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Jan ships with a default model folders containing recommended models"),(0,l.kt)("li",{parentName:"ul"},"Only the Model Object ",(0,l.kt)("inlineCode",{parentName:"li"},"json")," files are included"),(0,l.kt)("li",{parentName:"ul"},"Users must later explicitly download the model binaries")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sh"},"models/\n    mistral-7b/\n        mistral-7b.json\n    hermes-7b/\n        hermes-7b.json\n")),(0,l.kt)("h3",{id:"multiple-quantizations"},"Multiple quantizations"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Each quantization has its own ",(0,l.kt)("inlineCode",{parentName:"li"},"Jan Model Object")," file")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sh"},"llama2-7b-gguf/\n    llama2-7b-gguf-Q2.json\n    llama2-7b-gguf-Q3_K_L.json\n    .bin\n")),(0,l.kt)("h3",{id:"multiple-model-partitions"},"Multiple model partitions"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"A Model that is partitioned into several binaries use just 1 file")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sh"},"llava-ggml/\n    llava-ggml-Q5.json\n    .proj\n    ggml\n")),(0,l.kt)("h3",{id:"your-locally-fine-tuned-model"},"Your locally fine-tuned model"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"??")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sh"},"llama-70b-finetune/\n    llama-70b-finetune-q5.json\n    .bin\n")),(0,l.kt)("h2",{id:"jan-api"},"Jan API"),(0,l.kt)("h3",{id:"model-api-object"},"Model API Object"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"The ",(0,l.kt)("inlineCode",{parentName:"li"},"Jan Model Object")," maps into the ",(0,l.kt)("inlineCode",{parentName:"li"},"OpenAI Model Object"),"."),(0,l.kt)("li",{parentName:"ul"},"Properties marked with ",(0,l.kt)("inlineCode",{parentName:"li"},"*")," are compatible with the ",(0,l.kt)("a",{parentName:"li",href:"https://platform.openai.com/docs/api-reference/models"},"OpenAI ",(0,l.kt)("inlineCode",{parentName:"a"},"model")," object")),(0,l.kt)("li",{parentName:"ul"},"Note: The ",(0,l.kt)("inlineCode",{parentName:"li"},"Jan Model Object")," has additional properties when retrieved via its API endpoint.",(0,l.kt)("blockquote",{parentName:"li"},(0,l.kt)("p",{parentName:"blockquote"},"OpenAI Equivalent: ",(0,l.kt)("a",{parentName:"p",href:"https://platform.openai.com/docs/api-reference/models/object"},"https://platform.openai.com/docs/api-reference/models/object"))))),(0,l.kt)("h3",{id:"model-lifecycle"},"Model lifecycle"),(0,l.kt)("p",null,"Model has 4 states (enum)"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"to_download")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"downloading")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"ready")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"running"))),(0,l.kt)("h3",{id:"get-model"},"Get Model"),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},"OpenAI Equivalent: ",(0,l.kt)("a",{parentName:"p",href:"https://platform.openai.com/docs/api-reference/models/retrieve"},"https://platform.openai.com/docs/api-reference/models/retrieve")),(0,l.kt)("ul",{parentName:"blockquote"},(0,l.kt)("li",{parentName:"ul"},"Example request")),(0,l.kt)("pre",{parentName:"blockquote"},(0,l.kt)("code",{parentName:"pre",className:"language-shell"},"curl {JAN_URL}/v1/models/{model_id}\n")),(0,l.kt)("ul",{parentName:"blockquote"},(0,l.kt)("li",{parentName:"ul"},"Example response")),(0,l.kt)("pre",{parentName:"blockquote"},(0,l.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "id": "model-zephyr-7B",\n  "object": "model",\n  "created_at": 1686935002,\n  "owned_by": "thebloke",\n  "state": "running",\n  "source_url": "https://huggingface.co/TheBloke/zephyr-7B-beta-GGUF/blob/main/zephyr-7b-beta.Q4_K_M.gguf",\n  "parameters": {\n     "ctx_len": 2048,\n     "ngl": 100,\n     "embedding": true,\n     "n_parallel": 4,\n     "pre_prompt": "A chat between a curious user and an artificial intelligence",\n     "user_prompt": "USER: ",\n     "ai_prompt": "ASSISTANT: ",\n     "temperature": "0.7",\n     "token_limit": "2048",\n     "top_k": "0",\n     "top_p": "1",\n  },\n  "metadata": {\n     "engine": "llamacpp",\n     "quantization": "Q3_K_L",\n     "size": "7B",\n  }\n}\n')),(0,l.kt)("h3",{parentName:"blockquote",id:"list-models"},"List models"),(0,l.kt)("p",{parentName:"blockquote"},"Lists the currently available models, and provides basic information about each one such as the owner and availability.\nOpenAI Equivalent: ",(0,l.kt)("a",{parentName:"p",href:"https://platform.openai.com/docs/api-reference/models/list"},"https://platform.openai.com/docs/api-reference/models/list")),(0,l.kt)("ul",{parentName:"blockquote"},(0,l.kt)("li",{parentName:"ul"},"Example request")),(0,l.kt)("pre",{parentName:"blockquote"},(0,l.kt)("code",{parentName:"pre",className:"language-shell="},"curl {JAN_URL}/v1/models\n")),(0,l.kt)("ul",{parentName:"blockquote"},(0,l.kt)("li",{parentName:"ul"},"Example response")),(0,l.kt)("pre",{parentName:"blockquote"},(0,l.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "object": "list",\n  "data": [\n    {\n      "id": "model-zephyr-7B",\n      "object": "model",\n      "created_at": 1686935002,\n      "owned_by": "thebloke",\n      "state": "running"\n    },\n    {\n      "id": "ft-llama-70b-gguf",\n      "object": "model",\n      "created_at": 1686935002,\n      "owned_by": "you",\n      "state": "stopped"\n    },\n    {\n      "id": "model-azure-openai-gpt4-turbo",\n      "object": "model",\n      "created_at": 1686935002,\n      "owned_by": "azure_openai",\n      "state": "running"\n    },\n  ],\n  "object": "list"\n}\n')),(0,l.kt)("h3",{parentName:"blockquote",id:"delete-model"},"Delete Model"),(0,l.kt)("p",{parentName:"blockquote"},"OpenAI Equivalent: ",(0,l.kt)("a",{parentName:"p",href:"https://platform.openai.com/docs/api-reference/models/delete"},"https://platform.openai.com/docs/api-reference/models/delete"),"\n`- Example request"),(0,l.kt)("pre",{parentName:"blockquote"},(0,l.kt)("code",{parentName:"pre",className:"language-shell"},"curl -X DELETE {JAN_URL}/v1/models/{model_id}\n")),(0,l.kt)("ul",{parentName:"blockquote"},(0,l.kt)("li",{parentName:"ul"},"Example response")),(0,l.kt)("pre",{parentName:"blockquote"},(0,l.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "id": "model-zephyr-7B",\n  "object": "model",\n  "deleted": true,\n  "state": "to_download"\n}\n')),(0,l.kt)("h3",{parentName:"blockquote",id:"start-model"},"Start Model"),(0,l.kt)("p",{parentName:"blockquote"},"Jan-only endpoint\nThe request to start ",(0,l.kt)("inlineCode",{parentName:"p"},"model")," by changing model state from ",(0,l.kt)("inlineCode",{parentName:"p"},"ready")," to ",(0,l.kt)("inlineCode",{parentName:"p"},"running")),(0,l.kt)("ul",{parentName:"blockquote"},(0,l.kt)("li",{parentName:"ul"},"Example request")),(0,l.kt)("pre",{parentName:"blockquote"},(0,l.kt)("code",{parentName:"pre",className:"language-shell"},"curl -X PUT {JAN_URL}/v1/models{model_id}/start\n")),(0,l.kt)("ul",{parentName:"blockquote"},(0,l.kt)("li",{parentName:"ul"},"Example response")),(0,l.kt)("pre",{parentName:"blockquote"},(0,l.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "id": "model-zephyr-7B",\n  "object": "model",\n  "state": "running"\n}\n')),(0,l.kt)("h3",{parentName:"blockquote",id:"stop-model"},"Stop Model"),(0,l.kt)("p",{parentName:"blockquote"},"Jan-only endpoint\nThe request to start ",(0,l.kt)("inlineCode",{parentName:"p"},"model")," by changing model state from ",(0,l.kt)("inlineCode",{parentName:"p"},"running")," to ",(0,l.kt)("inlineCode",{parentName:"p"},"ready")),(0,l.kt)("ul",{parentName:"blockquote"},(0,l.kt)("li",{parentName:"ul"},"Example request")),(0,l.kt)("pre",{parentName:"blockquote"},(0,l.kt)("code",{parentName:"pre",className:"language-shell"},"curl -X PUT {JAN_URL}/v1/models/{model_id}/stop\n")),(0,l.kt)("ul",{parentName:"blockquote"},(0,l.kt)("li",{parentName:"ul"},"Example response")),(0,l.kt)("pre",{parentName:"blockquote"},(0,l.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "id": "model-zephyr-7B",\n  "object": "model",\n  "state": "ready"\n}\n')),(0,l.kt)("h3",{parentName:"blockquote",id:"download-model"},"Download Model"),(0,l.kt)("p",{parentName:"blockquote"},"Jan-only endpoint\nThe request to download ",(0,l.kt)("inlineCode",{parentName:"p"},"model")," by changing model state from ",(0,l.kt)("inlineCode",{parentName:"p"},"to_download")," to ",(0,l.kt)("inlineCode",{parentName:"p"},"downloading")," then ",(0,l.kt)("inlineCode",{parentName:"p"},"ready"),"once it's done."),(0,l.kt)("ul",{parentName:"blockquote"},(0,l.kt)("li",{parentName:"ul"},"Example request")),(0,l.kt)("pre",{parentName:"blockquote"},(0,l.kt)("code",{parentName:"pre",className:"language-shell"},"curl -X POST {JAN_URL}/v1/models/\n")),(0,l.kt)("ul",{parentName:"blockquote"},(0,l.kt)("li",{parentName:"ul"},"Example response")),(0,l.kt)("pre",{parentName:"blockquote"},(0,l.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "id": "model-zephyr-7B",\n  "object": "model",\n  "state": "downloading"\n}\n'))))}s.isMDXComponent=!0}}]);