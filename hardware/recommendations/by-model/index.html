<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-hardware/recommendations/by-model" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.3">
<title data-rh="true">Recommended AI Hardware by Model | Jan</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://jan.ai/img/jan-social-card.png"><meta data-rh="true" name="twitter:image" content="https://jan.ai/img/jan-social-card.png"><meta data-rh="true" property="og:url" content="https://jan.ai/hardware/recommendations/by-model"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Recommended AI Hardware by Model | Jan"><meta data-rh="true" name="description" content="Codellama 34b"><meta data-rh="true" property="og:description" content="Codellama 34b"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://jan.ai/hardware/recommendations/by-model"><link data-rh="true" rel="alternate" href="https://jan.ai/hardware/recommendations/by-model" hreflang="en"><link data-rh="true" rel="alternate" href="https://jan.ai/hardware/recommendations/by-model" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.8a275414.css">
<link rel="preload" href="/assets/js/runtime~main.857ac3fc.js" as="script">
<link rel="preload" href="/assets/js/main.ada1e6de.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Jan Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/logo.svg" alt="Jan Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Jan</b></a><a class="navbar__item navbar__link" href="/events/hcmc-oct23">Company</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/janhq/jan" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><main class="docMainContainer_gTbr docMainContainerEnhanced_Uz_u"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Recommended AI Hardware by Model</h1></header><h2 class="anchor anchorWithStickyNavbar_LWe7" id="codellama-34b">Codellama 34b<a href="#codellama-34b" class="hash-link" aria-label="Direct link to Codellama 34b" title="Direct link to Codellama 34b">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="system-requirements">System Requirements:<a href="#system-requirements" class="hash-link" aria-label="Direct link to System Requirements:" title="Direct link to System Requirements:">​</a></h3><p><strong>For example</strong>: If you want to use <a href="https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GPTQ/tree/main" target="_blank" rel="noopener noreferrer">Codellama 7B</a> models on your own computer, you can take advantage of your GPU and run this with GPTQ file models.</p><p>GPTQ is a format that compresses the model parameters to 4-bit, which reduces the VRAM requirements significantly. You can use the <a href="https://github.com/oobabooga/text-generation-webui" target="_blank" rel="noopener noreferrer">oobabooga webui</a> or <a href="https://jan.ai/" target="_blank" rel="noopener noreferrer">JanAI</a>, which are simple interfaces that let you interact with different LLMS on your browser. It is pretty easy to set up and run. You can install it on Windows or Linux. (linked it to our installation page)</p><p><strong>For 7B Parameter Models (4-bit Quantization)</strong></p><table><thead><tr><th>Format</th><th>RAM Requirements</th><th>VRAM Requirements</th><th>Minimum recommended GPU</th></tr></thead><tbody><tr><td>GPTQ (GPU inference)</td><td>6GB (Swap to Load<!-- -->*<!-- -->)</td><td>6GB</td><td>GTX 1660, 2060,RTX 3050, 3060 AMD 5700 XT</td></tr><tr><td>GGML / GGUF (CPU inference)</td><td>4GB</td><td>300MB</td><td></td></tr><tr><td>Combination of GPTQ and GGML / GGUF (offloading)</td><td>2GB</td><td>2GB</td><td></td></tr></tbody></table><p><strong>For 13B Parameter Models (4-bit Quantization)</strong></p><table><thead><tr><th>Format</th><th>RAM Requirements</th><th>VRAM Requirements</th><th>Minimum recommended GPU</th></tr></thead><tbody><tr><td>GPTQ (GPU inference)</td><td>12GB (Swap to Load<!-- -->*<!-- -->)</td><td>10GB</td><td></td></tr><tr><td>GGML / GGUF (CPU inference)</td><td>8GB</td><td>500MB</td><td>AMD 6900 XT, RTX 2060 12GB, 3060 12GB, 3080, A2000</td></tr><tr><td>Combination of GPTQ and GGML / GGUF (offloading)</td><td>10GB</td><td>10GB</td><td></td></tr></tbody></table><p><strong>For 34B Parameter Models (4-bit Quantization)</strong></p><table><thead><tr><th>Format</th><th>RAM Requirements</th><th>VRAM Requirements</th><th>Minimum recommended GPU</th></tr></thead><tbody><tr><td>GPTQ (GPU inference)</td><td>32GB (Swap to Load<!-- -->*<!-- -->)</td><td>20GB</td><td></td></tr><tr><td>GGML / GGUF (CPU inference)</td><td>20GB</td><td>500MB</td><td>RTX 3080 20GB, A4500, A5000, 3090, 4090, 6000, Tesla V100, Tesla P40</td></tr><tr><td>Combination of GPTQ and GGML / GGUF (offloading)</td><td>10GB</td><td>4GB</td><td></td></tr></tbody></table><p><strong>For 7B Parameter Models (8-bit Quantization)</strong></p><table><thead><tr><th>Format</th><th>RAM Requirements</th><th>VRAM Requirements</th><th>Minimum recommended GPU</th></tr></thead><tbody><tr><td>GPTQ (GPU inference)</td><td>24GB (Swap to Load<!-- -->*<!-- -->)</td><td>12GB</td><td>RTX 3080, RTX 3080 Ti, RTX 3090, A5000</td></tr><tr><td>GGML / GGUF (CPU inference)</td><td>16GB</td><td>1GB</td><td>RTX 3060 12GB, RTX 3070, A2000</td></tr><tr><td>Combination of GPTQ and GGML / GGUF (offloading)</td><td>12GB</td><td>4GB</td><td>RTX 3060, RTX 3060 Ti, A2000</td></tr></tbody></table><p><strong>For 13B Parameter Models (8-bit Quantization)</strong></p><table><thead><tr><th>Format</th><th>RAM Requirements</th><th>VRAM Requirements</th><th>Minimum recommended GPU</th></tr></thead><tbody><tr><td>GPTQ (GPU inference)</td><td>36GB (Swap to Load<!-- -->*<!-- -->)</td><td>20GB</td><td>RTX 4090, A6000, A6000 Ti, A8000</td></tr><tr><td>GGML / GGUF (CPU inference)</td><td>24GB</td><td>2GB</td><td>RTX 3080 20GB, RTX 3080 Ti, A5000</td></tr><tr><td>Combination of GPTQ and GGML / GGUF (offloading)</td><td>20GB</td><td>8GB</td><td>RTX 3080, RTX 3080 Ti, A5000</td></tr></tbody></table><p><strong>For 34B Parameter Models (8-bit Quantization)</strong></p><table><thead><tr><th>Format</th><th>RAM Requirements</th><th>VRAM Requirements</th><th>Minimum recommended GPU</th></tr></thead><tbody><tr><td>GPTQ (GPU inference)</td><td>64GB (Swap to Load<!-- -->*<!-- -->)</td><td>40GB</td><td>A8000, A8000 Ti, A9000</td></tr><tr><td>GGML / GGUF (CPU inference)</td><td>40GB</td><td>2GB</td><td>RTX 4090, A6000, A6000 Ti, A8000</td></tr><tr><td>Combination of GPTQ and GGML / GGUF (offloading)</td><td>48GB</td><td>20GB</td><td>RTX 4090, A6000, A6000 Ti, A8000</td></tr></tbody></table><blockquote><p>📝 <strong>Note</strong>: System RAM, not VRAM, required to load the model, in addition to having enough VRAM. Not required to run the model. You can use swap space if you do not have enough RAM.</p></blockquote><h3 class="anchor anchorWithStickyNavbar_LWe7" id="performance-recommendations">Performance Recommendations:<a href="#performance-recommendations" class="hash-link" aria-label="Direct link to Performance Recommendations:" title="Direct link to Performance Recommendations:">​</a></h3><ol><li><strong>Optimal Performance</strong>: To achieve the best performance when working with CodeLlama models, consider investing in a high-end GPU such as NVIDIA&#x27;s latest RTX 3090 or RTX 4090. For the largest models like the 65B and 70B, a dual GPU setup is recommended. Additionally, ensure your system boasts sufficient RAM, with a minimum of 16 GB, although 64 GB is ideal for seamless operation.</li><li><strong>Budget-Friendly Approach</strong>: If budget constraints are a concern, focus on utilizing CodeLlama GGML/GGUF models that can comfortably fit within your system&#x27;s available RAM. Keep in mind that while you can allocate some model weights to the system RAM to save GPU memory, this may result in a performance trade-off.</li></ol><blockquote><p>📝 <strong>Note</strong>: It&#x27;s essential to note that these recommendations are guidelines, and the actual performance you experience will be influenced by various factors. These factors include the specific task you&#x27;re performing, the implementation of the model, and the concurrent system processes. To optimize your setup, consider these recommendations as a starting point and adapt them to your unique requirements and constraints.</p></blockquote></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/janhq/jan/tree/main/docs/docs/hardware/recommendations/by-model.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2023-10-17T06:37:36.000Z">Oct 17, 2023</time></b> by <b>0xSage</b></span></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#codellama-34b" class="table-of-contents__link toc-highlight">Codellama 34b</a><ul><li><a href="#system-requirements" class="table-of-contents__link toc-highlight">System Requirements:</a></li><li><a href="#performance-recommendations" class="table-of-contents__link toc-highlight">Performance Recommendations:</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Jan</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/">Home</a></li><li class="footer__item"><a class="footer__link-item" href="/platform">Platform</a></li><li class="footer__item"><a class="footer__link-item" href="/solutions">Solutions</a></li></ul></div><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs">Docs</a></li><li class="footer__item"><a class="footer__link-item" href="/hardware">Hardware</a></li><li class="footer__item"><a class="footer__link-item" href="/api">API</a></li><li class="footer__item"><a class="footer__link-item" href="/changelog">Changelog</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.gg/FTk2MvZwJH" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/jan_dotai" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Company</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/about">About</a></li><li class="footer__item"><a href="https://janai.bamboohr.com/careers" target="_blank" rel="noopener noreferrer" class="footer__link-item">Careers<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/janhq/jan" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Jan AI Pte Ltd.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.857ac3fc.js"></script>
<script src="/assets/js/main.ada1e6de.js"></script>
</body>
</html>